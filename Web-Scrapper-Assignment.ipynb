{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e060ec63-6405-4ef5-ac15-7ac8d02f294a",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\n",
    "\n",
    "Answer(Q1):\n",
    "\n",
    "If we want to get large amounts of information from a website as quickly as possible, we can use web scrapping, that uses intelligence automation methods to get thousands or even millions of data sets in a smaller amount of time. \n",
    "\n",
    "three areas where Web Scraping is used to get data:\n",
    "\n",
    "1.Machine Learning :\n",
    "\n",
    "large amounts of data from a website to train a Machine Learning algorithm\n",
    "\n",
    "2.Lead Generation for Marketing: \n",
    "\n",
    "Scrape email addresses and phone numbers from Yellow Pages Scrape business contact details from Google Maps Listings\n",
    "\n",
    "3.Real Estate: \n",
    "\n",
    "Scrape real estate websites for property data\n",
    "\n",
    "4.DATA ANALYSIS:\n",
    "\n",
    "Using a Web Scraper you can extract data from multiple websites to a single spreadsheet (or database) so that it becomes easy for you to analyze (or even visualize) the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfeebde9-f871-41d3-a3f8-19330e9b84ad",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?\n",
    "\n",
    "Answer(Q2):\n",
    "\n",
    "Data Scraping Techniques:\n",
    "\n",
    "   Here are a few techniques commonly used to scrape data from websites. In general, all web scraping techniques retrieve content from websites, process it using a scraping engine, and generate one or more data files with the extracted content.\n",
    "   \n",
    "HTML Parsing\n",
    "\n",
    "DOM Parsing\n",
    "\n",
    "Vertical Aggregation\n",
    "\n",
    "XPath\n",
    "\n",
    "Google Sheets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610a3e05-93d5-4e4b-9c8f-9817f78571cf",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?\n",
    "\n",
    "Answer(Q3):\n",
    "\n",
    "Beautiful Soup is a Python package for parsing HTML and XML documents (including having malformed markup, i.e. non-closed tags, so named after tag soup). \n",
    "\n",
    "It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e665283e-7dbe-4a98-b973-ca2138eacc8f",
   "metadata": {},
   "source": [
    "Q4. Why is flask used in this Web Scraping project?\n",
    "\n",
    "Answer(Q4):\n",
    "\n",
    "Flask is a lightweight framework to build websites. We'll use this to parse our collected data and display it as HTML in a new HTML file. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faeaa6e-4daa-48dc-9a7d-edf24e4bbc91",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "\n",
    "Answer(Q5):\n",
    "\n",
    "1.AWS Elastic Beanstalk: Used to deploy the Flask web Scrapper Application\n",
    "\n",
    "2.Code Pipeline: This service is used to connect the Application committed in github to Elastic Beanstalk to deploy it.\n",
    "\n",
    "AWS Elastic Beanstalk:\n",
    "   \n",
    "   Elastic Beanstalk, we can quickly deploy and manage applications in the AWS Cloud without having to learn about the infrastructure that runs those applications. Elastic Beanstalk reduces management complexity without restricting choice or control. You simply upload your application, and Elastic Beanstalk automatically handles the details of capacity provisioning, load balancing, scaling, and application health monitoring.\n",
    "\n",
    "Elastic Beanstalk supports applications developed in Go, Java, .NET, Node.js, PHP, Python, and Ruby. When we deploy your application, Elastic Beanstalk builds the selected supported platform version and provisions one or more AWS resources, such as Amazon EC2 instances, to run our application.\n",
    "\n",
    "We can interact with Elastic Beanstalk by using the Elastic Beanstalk console, the AWS Command Line Interface (AWS CLI), or eb, a high-level CLI designed specifically for Elastic Beanstalk.\n",
    "\n",
    "Code Pipeline:\n",
    "\n",
    "   AWS CodePipeline is a continuous delivery service we can use to model, visualize, and automate the steps required to release your software. We can quickly model and configure the different stages of a software release process. CodePipeline automates the steps required to release our software changes continuously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63607ebe-1509-4ab3-94b7-4a6be322e427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
